# T5_finetune

Code for T5 finetune - closed book multihop QA   

* Setting:
```
pytorch-lightning==0.9.0
nlp
wandb
transformers
sentencepiece
```
* possible models to use:
	* [t5-base (small/large/3b/11b)](https://huggingface.co/t5-base)
	* [t5-large-ssm](https://huggingface.co/google/t5-large-ssm)
	* [t5-small-ssm-nq (small/large/xl/xxl/3b/11b)](https://huggingface.co/google/t5-small-ssm-nq)
	* [triviaqa-t5-base](https://huggingface.co/deep-learning-analytics/triviaqa-t5-base)
	* [t5-base-finetuned-quartz](https://huggingface.co/mrm8488/t5-base-finetuned-quartz)

* base code from [closedbook-triviaQA](https://github.com/priya-dwivedi/Deep-Learning/blob/master/trivia-bot-t5/T5-ClosedBook-TriviaQA-Github.ipynb)

